{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Model Development, Tuning, and Evaluation\n",
    "\n",
    "Goal: Achieve highest accuracy possible in using classification to distinguish between positive and negative textual reviews.\n",
    "\n",
    "Models to be developed:\n",
    "1. Logistic Regression\n",
    "2. SVM\n",
    "3. XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading in Data\n",
    "Textual data has already been vectorized using Word2Vec resulting in 500 features representing each review and 1 target feature, Sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49582, 501)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.006993</td>\n",
       "      <td>-0.017787</td>\n",
       "      <td>0.010712</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>-0.202235</td>\n",
       "      <td>-0.010649</td>\n",
       "      <td>-0.035199</td>\n",
       "      <td>0.142727</td>\n",
       "      <td>-0.071552</td>\n",
       "      <td>0.089088</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098540</td>\n",
       "      <td>0.070369</td>\n",
       "      <td>-0.056713</td>\n",
       "      <td>-0.140328</td>\n",
       "      <td>-0.034548</td>\n",
       "      <td>-0.081482</td>\n",
       "      <td>0.029489</td>\n",
       "      <td>0.045794</td>\n",
       "      <td>-0.007057</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000186</td>\n",
       "      <td>-0.085118</td>\n",
       "      <td>0.075544</td>\n",
       "      <td>0.031908</td>\n",
       "      <td>-0.283040</td>\n",
       "      <td>-0.081430</td>\n",
       "      <td>-0.002124</td>\n",
       "      <td>0.162392</td>\n",
       "      <td>-0.035978</td>\n",
       "      <td>0.026303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012751</td>\n",
       "      <td>0.048073</td>\n",
       "      <td>0.011637</td>\n",
       "      <td>-0.101292</td>\n",
       "      <td>-0.059473</td>\n",
       "      <td>-0.080104</td>\n",
       "      <td>0.049169</td>\n",
       "      <td>0.067283</td>\n",
       "      <td>0.023935</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085147</td>\n",
       "      <td>-0.115304</td>\n",
       "      <td>-0.024152</td>\n",
       "      <td>0.015084</td>\n",
       "      <td>-0.285222</td>\n",
       "      <td>-0.051906</td>\n",
       "      <td>0.040571</td>\n",
       "      <td>0.193170</td>\n",
       "      <td>-0.089491</td>\n",
       "      <td>0.084364</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043263</td>\n",
       "      <td>0.089965</td>\n",
       "      <td>-0.060650</td>\n",
       "      <td>-0.077252</td>\n",
       "      <td>-0.008706</td>\n",
       "      <td>-0.093932</td>\n",
       "      <td>0.025079</td>\n",
       "      <td>0.094748</td>\n",
       "      <td>-0.069459</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.045757</td>\n",
       "      <td>-0.051800</td>\n",
       "      <td>-0.002757</td>\n",
       "      <td>0.037521</td>\n",
       "      <td>-0.245770</td>\n",
       "      <td>-0.061446</td>\n",
       "      <td>-0.015328</td>\n",
       "      <td>0.127537</td>\n",
       "      <td>-0.015892</td>\n",
       "      <td>0.099974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057313</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>-0.008593</td>\n",
       "      <td>-0.031528</td>\n",
       "      <td>-0.036333</td>\n",
       "      <td>-0.091298</td>\n",
       "      <td>-0.032505</td>\n",
       "      <td>0.066214</td>\n",
       "      <td>0.027054</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005742</td>\n",
       "      <td>-0.050887</td>\n",
       "      <td>-0.030296</td>\n",
       "      <td>0.004247</td>\n",
       "      <td>-0.251409</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.021926</td>\n",
       "      <td>0.206545</td>\n",
       "      <td>-0.048080</td>\n",
       "      <td>0.125729</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.102182</td>\n",
       "      <td>0.064460</td>\n",
       "      <td>-0.025878</td>\n",
       "      <td>-0.123427</td>\n",
       "      <td>-0.081694</td>\n",
       "      <td>-0.110009</td>\n",
       "      <td>0.020667</td>\n",
       "      <td>0.072723</td>\n",
       "      <td>-0.057010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.006993 -0.017787  0.010712  0.001786 -0.202235 -0.010649 -0.035199   \n",
       "1 -0.000186 -0.085118  0.075544  0.031908 -0.283040 -0.081430 -0.002124   \n",
       "2  0.085147 -0.115304 -0.024152  0.015084 -0.285222 -0.051906  0.040571   \n",
       "3  0.045757 -0.051800 -0.002757  0.037521 -0.245770 -0.061446 -0.015328   \n",
       "4  0.005742 -0.050887 -0.030296  0.004247 -0.251409 -0.100000  0.021926   \n",
       "\n",
       "          7         8         9  ...       491       492       493       494  \\\n",
       "0  0.142727 -0.071552  0.089088  ... -0.098540  0.070369 -0.056713 -0.140328   \n",
       "1  0.162392 -0.035978  0.026303  ...  0.012751  0.048073  0.011637 -0.101292   \n",
       "2  0.193170 -0.089491  0.084364  ... -0.043263  0.089965 -0.060650 -0.077252   \n",
       "3  0.127537 -0.015892  0.099974  ... -0.057313  0.016450 -0.008593 -0.031528   \n",
       "4  0.206545 -0.048080  0.125729  ... -0.102182  0.064460 -0.025878 -0.123427   \n",
       "\n",
       "        495       496       497       498       499  sentiment  \n",
       "0 -0.034548 -0.081482  0.029489  0.045794 -0.007057          1  \n",
       "1 -0.059473 -0.080104  0.049169  0.067283  0.023935          1  \n",
       "2 -0.008706 -0.093932  0.025079  0.094748 -0.069459          1  \n",
       "3 -0.036333 -0.091298 -0.032505  0.066214  0.027054          0  \n",
       "4 -0.081694 -0.110009  0.020667  0.072723 -0.057010          1  \n",
       "\n",
       "[5 rows x 501 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('IMDb_nonstemmed_w2v_500v_data.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting into Training and Testing sets\n",
    "We will be splitting the data into 80% training and 20% testing sets.\n",
    "\n",
    "The __training set__ will be used for __fitting__.\n",
    "\n",
    "The __testing set__ will be used for __final model evaluations__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all features except target\n",
    "X = df.drop('sentiment', axis=1)    # to be used for \n",
    "# only target feature (sentiment)\n",
    "y = df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.20, random_state=34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Note: For the following models we will be using the optimal hyperparameters found when training models using a vector size of 200__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8909    0.8791    0.8849      4921\n",
      "           1     0.8824    0.8939    0.8881      4996\n",
      "\n",
      "    accuracy                         0.8866      9917\n",
      "   macro avg     0.8866    0.8865    0.8865      9917\n",
      "weighted avg     0.8866    0.8866    0.8865      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression(C = 1.0, max_iter=1000, penalty='l1', solver = 'saga')\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred = lr_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. SVM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 Initial Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8880    0.8785    0.8832      4921\n",
      "           1     0.8816    0.8909    0.8862      4996\n",
      "\n",
      "    accuracy                         0.8847      9917\n",
      "   macro avg     0.8848    0.8847    0.8847      9917\n",
      "weighted avg     0.8848    0.8847    0.8847      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_model = LinearSVC(C = 10, loss = 'squared_hinge', max_iter = 1000, penalty= 'l2')\n",
    "svc_model.fit(X_train, y_train)\n",
    "y_pred = svc_model.predict(X_test)\n",
    "print(classification_report(y_test,y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8772    0.8476    0.8621      4921\n",
      "           1     0.8547    0.8831    0.8687      4996\n",
      "\n",
      "    accuracy                         0.8655      9917\n",
      "   macro avg     0.8659    0.8653    0.8654      9917\n",
      "weighted avg     0.8659    0.8655    0.8654      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(learning_rate = 0.2, max_depth = 9, ns_estimator = 100)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
