{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Data Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewers mentioned watching oz episode yo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres family little boy jake thinks...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  one reviewers mentioned watching oz episode yo...          1\n",
       "1  wonderful little production filming technique ...          1\n",
       "2  thought wonderful way spend time hot summer we...          1\n",
       "3  basically theres family little boy jake thinks...          0\n",
       "4  petter matteis love time money visually stunni...          1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv('cleaned_stemmed_IMDb_reviews.csv')\n",
    "df = pd.read_csv('cleaned_non_stemmed_IMDb_reviews.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Tokenization of our reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing reviews\n",
    "tokenized_review = df['review'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Training a Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTING MODEL PARAMETERS\n",
    "model_w2v = gensim.models.Word2Vec(\n",
    "    tokenized_review,\n",
    "    vector_size = 1000, # desired number of features\n",
    "    window = 5, # context window\n",
    "    min_count = 2, # ignore all words with total frequency lower than 2\n",
    "    sg = 1,\n",
    "    hs = 0,\n",
    "    negative = 10,\n",
    "    workers = 10,\n",
    "    seed = 34\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110898761, 117768600)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAINING MODEL ON CORPUS\n",
    "model_w2v.train(\n",
    "    tokenized_review,\n",
    "    total_examples = len(df['review']),\n",
    "    epochs = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Transforming our tokenized features into vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNC: CREATES VECTOR FOR EACH REVIEW BY TAKING THE AVERAGE OF THE VECTORS OF WORDS PRESENT IN REVIEW\n",
    "def word_vector(tokens, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += model_w2v.wv[word].reshape((1, size))\n",
    "            count += 1\n",
    "        except KeyError:    # case where token is not in vocab\n",
    "            continue\n",
    "    if count !=0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49582, 1000)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying above method to each review\n",
    "wordvec_arrays = np.zeros((len(tokenized_review), 1000))\n",
    "for i in range(len(tokenized_review)):\n",
    "    wordvec_arrays[i,:] = word_vector(tokenized_review[i], 1000)\n",
    "\n",
    "wordvec_df = pd.DataFrame(wordvec_arrays)\n",
    "wordvec_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Rejoining our vectors alongside our target feature and saving to .CSV file to be used later for modeling development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49582, 1001)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_df['sentiment'] = df['sentiment']\n",
    "wordvec_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordvec_df.to_csv('IMDb_nonstemmed_w2v_1000v_data.csv', index=False)\n",
    "# wordvec_df.to_csv('IMDb_nonstemmed_w2v_500v_data.csv', index=False)\n",
    "# wordvec_df.to_csv('IMDb_stemmed_w2v_data.csv', index=False)\n",
    "# wordvec_df.to_csv('IMDb_nonstemmed_vectorized_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
