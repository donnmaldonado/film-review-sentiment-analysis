{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Film Reviews: Sentiment Analysis\n",
    "\n",
    "## Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "##### Now that our data has been processed, it is now ready to be vectorized.\n",
    "\n",
    "__Vectorization__ is a technique used to convert text data into a numerical format that ML algorithms can understand. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one review mention watch oz episod youll hook ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonder littl product film techniqu unassum old...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonder way spend time hot summer weeke...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basic there famili littl boy jake think there ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei love time money visual stun film...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  one review mention watch oz episod youll hook ...          1\n",
       "1  wonder littl product film techniqu unassum old...          1\n",
       "2  thought wonder way spend time hot summer weeke...          1\n",
       "3  basic there famili littl boy jake think there ...          0\n",
       "4  petter mattei love time money visual stun film...          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('processed_IMDb_reviews.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train test split\n",
    "x = df['review']    # will be used for training and validating (hyperparameter tuning using k-fold)\n",
    "y = df['sentiment'] # will be used for final evaluation\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.20, random_state=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape: (39665,)\n",
      "Y train shape: (39665,)\n",
      "X test shape: (9917,)\n",
      "Y test shape: (9917,)\n"
     ]
    }
   ],
   "source": [
    "print(f'X train shape: {x_train.shape}')\n",
    "print(f'Y train shape: {y_train.shape}')\n",
    "print(f'X test shape: {x_test.shape}')\n",
    "print(f'Y test shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer= TfidfVectorizer()\n",
    "# train TFDIF model on training data\n",
    "# transform training data\n",
    "x_train_vect = vectorizer.fit_transform(x_train)\n",
    "# transform testing data\n",
    "x_test_vect = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train vectorized shape:   (39665, 150335)\n",
      "X test vectorized shape:    (9917, 150335)\n"
     ]
    }
   ],
   "source": [
    "print(f'X train vectorized shape:   {x_train_vect.get_shape()}')\n",
    "print(f'X test vectorized shape:    {x_test_vect.get_shape()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's do some inital modeling.\n",
    "These models are just to get a feel for a data (without hyperparameter tuning) and will be discarded therefore we will be use our previous training and testing split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88      4904\n",
      "           1       0.88      0.90      0.88      5013\n",
      "\n",
      "    accuracy                           0.88      9917\n",
      "   macro avg       0.88      0.88      0.88      9917\n",
      "weighted avg       0.88      0.88      0.88      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc = LinearSVC(random_state=1)\n",
    "svc.fit(x_train_vect, y_train)\n",
    "y_pred_svc = svc.predict(x_test_vect)\n",
    "print(classification_report(y_test, y_pred_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector models typically require a their features to be standardized, however, after doing some research we found that it might not be necessary if those features have already been transformed using TF-IDF.\n",
    "\n",
    "Anyhow, we decided to try to see if such standardization to see if it provided any benefit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      4904\n",
      "           1       0.84      0.83      0.83      5013\n",
      "\n",
      "    accuracy                           0.83      9917\n",
      "   macro avg       0.83      0.83      0.83      9917\n",
      "weighted avg       0.83      0.83      0.83      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler(with_mean=False)\n",
    "x_train_sc = scaler.fit(x_train_vect)\n",
    "x_train_vect_SCALED = scaler.transform(x_train_vect)\n",
    "x_test_vect_SCALED = scaler.transform(x_test_vect)\n",
    "\n",
    "svc_scaled = LinearSVC(random_state=1)\n",
    "svc_scaled.fit(x_train_vect_SCALED, y_train)\n",
    "y_pred_svc = svc.predict(x_test_vect_SCALED)\n",
    "print(classification_report(y_test, y_pred_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, applying a standard scaler transformation to the vectorized data yielded worse results than without. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88      4904\n",
      "           1       0.88      0.89      0.89      5013\n",
      "\n",
      "    accuracy                           0.89      9917\n",
      "   macro avg       0.89      0.89      0.89      9917\n",
      "weighted avg       0.89      0.89      0.89      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000, solver='saga')\n",
    "lr.fit(x_train_vect, y_train)\n",
    "y_pred_lr = lr.predict(x_test_vect)\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
